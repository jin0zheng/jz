3.6-3.10
	1.入职材料填写
	2.阅读入职须知
	3.跟随胡博（胡立天）学习手势的采集、筛选和标注 
	4.采集两个人的手势数据 
	5.标记完成5000张手势图片
	
3.13-3.17
	1.标注上周采集的手势9616张。
	2.整理《手机图片标注要求》和《手势图片标注要求》
	3.安装relsense工具和相关python环境，用于调用鱼眼相机,已完成pycharm下的reasense调用
		a.安装RealSense.SDK.exe
		b.升级RealSense.SDK的相机固件程序
		c.安装相关python库：pyrealsense,numpy,opencv-python,numpy……
		d.运行测试代码，验证环境
	4.学习卷积神经网络在手势识别中的应用的相关知识
		a.数据预处理：将采集的手势分类编号，并标注图片中的手势，其中标注相当于输入，编号为输出，算法学习其中的映射关系，进而强化输入输出的映射能力。
		b.训练完的模型对数据的处理：识别环境中的手势，并对手势分类
	5.了解银狐算法需求并学习相关知识
	
3.20-3.24
	1.用笔记本运行脚本调用鱼眼相机采集手势的背景图片5400张，现采集室内部分
	2.使用抓图脚本，去除两组黑布场景的8000张手势图片中的黑布背景
		a.算法使用二值化处理将低于预设灰度值的区域置白，再用置白部分覆盖原图对应的低灰度区域
		b.不断调节预设灰度值，直到背景和手势较好的分离
	3.笔记本上调试手势采集脚本，编写批量获取标注坐标的脚本，为下周的采集做准备。
	4.采集5台眼镜的IMU数据
	
3.27-3.31
	1.采集手势的高亮背景
		灯光，日光，出口处
	2.采集两组高亮背景手势和一组黑布场景手势并标注完成
	3.和刘工完成上周的imu测试
	4.编写《算法测试方案》
	5.编写标注的辅助脚本
		按caps键完成鼠标释放+w+d，再次按caps键完成鼠标按下
		记录次数和每次的间隔时间

4.3-4.7
	1.采集林世军和吴迟的普通背景手势数据并标注
	2.采集手势负样本并筛选
	3.确认采集3种手势及其负样本的imu数据的流程
	4.采集3种手势的imu数据完成两组数据采集

4.10-4.14
	1.修改采集IUM动作识别计时脚本
		a.获取手机的时间，用于计算与电脑时间差，并写入mouselog.txt
		b.用pynput监听鼠标时间用于记录动作开始结束时间，以及撤回和清零
	2.采集8组手势的imu数据
	2.采集1组高亮背景手势数据，并旋转和标注,共计1400张
	3.采集两组手势识别的测试集，并做[-180,180]的旋转和标注，已完成2361
    4.补充腕掌负样本，采集3713张，标注完成3009
	5.介入slam测试，学习算法调用流程和常规配置项以及常用的shell命令
		a.打开4个Terminal，连接firefly主机，依次 start_sensor、slam程序、htop内存监控、bag rocord收集bag
		b.再打开一个Terminal，使用rviz连接firefly主机的slam程序
	6.测试slam算法，共测试7个场景，报告已发到slam测试沟通群，并将测试的截图、log、bag收集并上传到算法部的服务器

4.17-4.21
	1.标注剩余的手势识别测试集2263张
	2.采集两组背光手势并标注完成，共计4506张
	    a.寻找背光场景并采集，要求采集的手势较黑，纹理不清晰
	    b。标注采集的图片，标注中跳过不合适的图片
	    c.脚本删除未标注的图片
	3.为算法测试电脑配置pytorch的gpu环境
	    a.安装cuda和cudnn，配置相关环境变量
	    b.检查安装结果，C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1\extras\demo_suite
	    c.安装pytorch的gpu版本
	    d.torch.cuda.is_available()，检查是否可用
	4.安装和配置Ubuntu虚拟机
	    a.编写监控RX上slam服务内存的脚本，完成免密登录RX并编写启动传感器、内存监控、bag record、slam server的脚本
	    b.安装anaconda、vim、ros

4.23-5.6
    1.采集10组imu动作识别数据
    2.为虚拟机配置slam环境，并完成slam版本测试
    3.标注高亮背景的手势数据3174张，用于改善光源误识别为手势，
    4.采集一组标注背光畸变的手势，共计3199张
    	a.寻找背光场景并采集，要求采集时手在镜头的边缘，即获取畸变手势。
	    b。标注采集的图片，标注中跳过不合适的图片
	    c.脚本删除未标注的图片
    5.采集三组复杂背景数据并标注完成，将用于使模型适配不同背景，每组约1200张，共计3643张图片
    6.在笔记本上安装ubuntu20.0.4版本的系统


5.8-5.12
    1.在ubuntu系统上配置slam测试环境
    2.采集四组复杂背景的数据，每组约1500张，包括实验室、电梯过道、办公区、办公桌
    3.补采两组imu动作数据
    4.和刘亚平、杨鹏验证竞品眼镜ureal的slam算法
    5.使用yolo7模型训练手势自动标注模型，共训练三轮，每轮20epoch
        a.传入手动标注的img和anno，其中41499张手势数据训练，4622张用于模型测试
        b.使用YOLO7（You Only Look Once）模型训练
    6.使用训练好的模型进行手势识别，并转化为标注，目前处理开启delect_img保存情况下，处理1000图片耗时三分钟
        处理采集好的图片的大致思路如下：
        a.调用ori_img随机角度的旋转jpg
        b.使用模型预测图片中的手势，这将保存预测图像并将返回图片名、手势预测框的坐标、置信度写入txt
        c.筛选出txt中单个pic的多detect中最高置信度的预测框
        d.将图片名、手势预测框的坐标写入手势标注xml文件
        e.标注好的数据后，人工确认，矫正错误标注并删除不合格手势的标注，而后使用脚本删除无标注的pic
    7.编写imu标定验收方案

5.15-5.19
    1.开始采集RGB手势数据
    2.和开发确认imu标定验收方案

